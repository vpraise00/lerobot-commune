# Waypoint-based Heuristic Policy - ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

Waypoint PolicyëŠ” teleoperationì„ í†µí•´ ì €ì¥í•œ waypointë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒí•˜ëŠ” heuristic policyì…ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
- âœ… Teleoperationìœ¼ë¡œ waypoint ì €ì¥ (5~10ê°œ)
- âœ… ì €ì¥ëœ waypointë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ
- âœ… Proportional controlë¡œ ë¶€ë“œëŸ¬ìš´ ì´ë™
- âœ… Waypoint ë„ë‹¬ ê°ì§€ (tolerance ê¸°ë°˜)
- âœ… JSON í¬ë§·ìœ¼ë¡œ waypoint ì €ì¥/ë¡œë“œ

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1ë‹¨ê³„: Waypoint ì €ì¥

Teleoperationì„ í†µí•´ ì›í•˜ëŠ” ìœ„ì¹˜ë¡œ ë¡œë´‡ì„ ì´ë™í•˜ê³  waypointë¥¼ ì €ì¥í•©ë‹ˆë‹¤:

```bash
lerobot-save-waypoints \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_so101 \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=leader \
    --output_path=waypoints/pick_and_place.json \
    --max_waypoints=10
```

**ì¡°ì‘ ë°©ë²•:**
1. Leader ë¡œë´‡ìœ¼ë¡œ followerë¥¼ ì›í•˜ëŠ” ìœ„ì¹˜ë¡œ ì´ë™
2. í„°ë¯¸ë„ì—ì„œ `s` + ENTERë¥¼ ëˆŒëŸ¬ waypoint ì €ì¥
3. `q` + ENTERë¥¼ ëˆŒëŸ¬ ì €ì¥ ì™„ë£Œ

**ì €ì¥ë˜ëŠ” JSON í¬ë§·:**
```json
{
  "robot_type": "so101_follower",
  "num_waypoints": 5,
  "created_at": "2025-10-03 12:34:56",
  "waypoints": [
    {
      "index": 0,
      "state": {
        "shoulder_pan.pos": 0.0,
        "shoulder_lift.pos": 0.5,
        "elbow_flex.pos": -0.3,
        "wrist_flex.pos": 0.1,
        "wrist_roll.pos": 0.0,
        "gripper.pos": 1.0
      },
      "timestamp": 1728045296.123
    },
    ...
  ]
}
```

---

### 2ë‹¨ê³„: Waypoint ì¬ìƒ

ì €ì¥í•œ waypointë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒí•©ë‹ˆë‹¤:

```bash
lerobot-eval \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_so101 \
    --policy.type=heuristic \
    --policy.waypoints_path=waypoints/pick_and_place.json \
    --policy.waypoint_tolerance=0.01 \
    --policy.waypoint_speed=0.1 \
    --num_episodes=5
```

**íŒŒë¼ë¯¸í„° ì„¤ëª…:**
- `--policy.waypoints_path`: waypoint JSON íŒŒì¼ ê²½ë¡œ
- `--policy.waypoint_tolerance`: waypoint ë„ë‹¬ íŒì • ê±°ë¦¬ (ê¸°ë³¸: 0.01)
- `--policy.waypoint_speed`: ì´ë™ ì†ë„ ê³„ìˆ˜ (0.1 = ì—ëŸ¬ì˜ 10%ì”© ì´ë™)
- `--num_episodes`: ì¬ìƒ ë°˜ë³µ íšŸìˆ˜

---

## ğŸ“ í”„ë¡œê·¸ë˜ë° ë°©ì‹ ì‚¬ìš©

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from lerobot.policies.heuristic import HeuristicConfig, WaypointPolicy
from lerobot.robots.so101_follower import SO101Follower, SO101FollowerConfig
import torch

# ì„¤ì •
robot_config = SO101FollowerConfig(port="/dev/ttyACM0", id="my_so101")
policy_config = HeuristicConfig(
    waypoints_path="waypoints/pick_and_place.json",
    waypoint_tolerance=0.01,
    waypoint_speed=0.1
)

# ì´ˆê¸°í™”
robot = SO101Follower(robot_config)
robot.connect()
policy = WaypointPolicy(policy_config)

# ì œì–´ ë£¨í”„
for step in range(1000):
    # ê´€ì°°
    obs = robot.get_observation()
    batch = {
        "observation.state": torch.tensor([[
            obs["shoulder_pan.pos"],
            obs["shoulder_lift.pos"],
            obs["elbow_flex.pos"],
            obs["wrist_flex.pos"],
            obs["wrist_roll.pos"],
            obs["gripper.pos"],
        ]], dtype=torch.float32)
    }

    # ì•¡ì…˜ ê³„ì‚°
    action = policy.select_action(batch)

    # ë¡œë´‡ì— ì „ì†¡
    action_dict = {
        "shoulder_pan.pos": float(action[0, 0]),
        "shoulder_lift.pos": float(action[0, 1]),
        "elbow_flex.pos": float(action[0, 2]),
        "wrist_flex.pos": float(action[0, 3]),
        "wrist_roll.pos": float(action[0, 4]),
        "gripper.pos": float(action[0, 5]),
    }
    robot.send_action(action_dict)

    # ì™„ë£Œ ì²´í¬
    if policy.waypoints_completed:
        print("ëª¨ë“  waypoint ì™„ë£Œ!")
        break

robot.disconnect()
```

---

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. Waypointë¥¼ ì§ì ‘ ìƒì„±

JSON íŒŒì¼ì„ ì§ì ‘ ë§Œë“¤ì–´ì„œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:

```python
import json

waypoints_data = {
    "robot_type": "so101_follower",
    "num_waypoints": 3,
    "created_at": "2025-10-03 12:00:00",
    "waypoints": [
        {
            "index": 0,
            "state": {
                "shoulder_pan.pos": 0.0,
                "shoulder_lift.pos": 0.0,
                "elbow_flex.pos": 0.0,
                "wrist_flex.pos": 0.0,
                "wrist_roll.pos": 0.0,
                "gripper.pos": 1.0
            },
            "timestamp": 0
        },
        # ... more waypoints
    ]
}

with open("waypoints/custom.json", "w") as f:
    json.dump(waypoints_data, f, indent=2)
```

### 2. ì‹¤ì‹œê°„ìœ¼ë¡œ waypoint ì¶”ê°€

```python
class DynamicWaypointPolicy(WaypointPolicy):
    """ë™ì ìœ¼ë¡œ waypointë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” policy"""

    def add_waypoint(self, state_dict):
        """ìƒˆë¡œìš´ waypoint ì¶”ê°€"""
        self.waypoints.append(state_dict)
        print(f"Waypoint {len(self.waypoints)} ì¶”ê°€ë¨")

    def clear_waypoints(self):
        """ëª¨ë“  waypoint ì œê±°"""
        self.waypoints = []
        self.current_waypoint_idx = 0
        self.waypoints_completed = False
```

### 3. Waypoint ë³´ê°„ (Interpolation)

ë¶€ë“œëŸ¬ìš´ ê¶¤ì ì„ ìœ„í•´ waypoint ì‚¬ì´ë¥¼ ë³´ê°„:

```python
import numpy as np

class InterpolatedWaypointPolicy(WaypointPolicy):
    """Waypoint ì‚¬ì´ë¥¼ ì„ í˜• ë³´ê°„í•˜ëŠ” policy"""

    def __init__(self, config):
        super().__init__(config)
        self.interpolation_steps = 50  # ê° waypoint ì‚¬ì´ ìŠ¤í… ìˆ˜
        self.interpolated_waypoints = self._interpolate_waypoints()

    def _interpolate_waypoints(self):
        """Waypoint ì‚¬ì´ë¥¼ ì„ í˜• ë³´ê°„"""
        interpolated = []

        for i in range(len(self.waypoints) - 1):
            current = np.array(list(self.waypoints[i].values()))
            next_wp = np.array(list(self.waypoints[i + 1].values()))

            # ì„ í˜• ë³´ê°„
            for t in np.linspace(0, 1, self.interpolation_steps):
                interpolated_state = current * (1 - t) + next_wp * t
                interpolated.append(dict(zip(self.waypoints[i].keys(), interpolated_state)))

        return interpolated
```

---

## ğŸ“Š ì œì–´ ì•Œê³ ë¦¬ì¦˜

WaypointPolicyëŠ” ê°„ë‹¨í•œ **Proportional Control**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

```python
# í˜„ì¬ ìƒíƒœì™€ ëª©í‘œ waypoint ì‚¬ì´ì˜ ì˜¤ì°¨ ê³„ì‚°
error = target_waypoint - current_state

# ì˜¤ì°¨ì˜ ì¼ì • ë¹„ìœ¨ë§Œí¼ ì´ë™
action = current_state + error * waypoint_speed

# waypoint_speed = 0.1 ì´ë©´ ë§¤ ìŠ¤í…ë§ˆë‹¤ ì˜¤ì°¨ì˜ 10%ì”© ì´ë™
```

### íŒŒë¼ë¯¸í„° íŠœë‹

| íŒŒë¼ë¯¸í„° | ë‚®ì€ ê°’ | ë†’ì€ ê°’ |
|---------|--------|---------|
| `waypoint_speed` | ëŠë¦¬ê³  ë¶€ë“œëŸ¬ì›€ | ë¹ ë¥´ì§€ë§Œ ì˜¤ë²„ìŠˆíŒ… ê°€ëŠ¥ |
| `waypoint_tolerance` | ì •í™•í•˜ì§€ë§Œ ëŠë¦¼ | ë¹ ë¥´ì§€ë§Œ ë¶€ì •í™• |

**ê¶Œì¥ ê°’:**
- `waypoint_speed`: 0.05 ~ 0.2
- `waypoint_tolerance`: 0.005 ~ 0.02

---

## ğŸ¯ í™œìš© ì‚¬ë¡€

### 1. Pick and Place

```bash
# 1. Waypoint ì €ì¥
lerobot-save-waypoints \
    --output_path=waypoints/pick_and_place.json \
    --max_waypoints=6
# Waypoints: [ì´ˆê¸°ìœ„ì¹˜] -> [ë¬¼ì²´ ìœ„] -> [ë¬¼ì²´ ì¡ê¸°] -> [ë“¤ê¸°] -> [ëª©í‘œ ìœ„] -> [ë†“ê¸°]

# 2. ì¬ìƒ
lerobot-eval --policy.waypoints_path=waypoints/pick_and_place.json
```

### 2. ë°˜ë³µ ì‘ì—…

```bash
# ë™ì¼í•œ ì‘ì—…ì„ 100ë²ˆ ë°˜ë³µ
lerobot-eval \
    --policy.waypoints_path=waypoints/assembly.json \
    --num_episodes=100
```

### 3. ë°ì´í„° ìˆ˜ì§‘

Waypoint policyë¡œ ì¼ê´€ëœ ë°ì´í„°ë¥¼ ìˆ˜ì§‘:

```bash
lerobot-record \
    --policy.type=heuristic \
    --policy.waypoints_path=waypoints/task.json \
    --dataset.num_episodes=50
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. Waypointê°€ ì €ì¥ë˜ì§€ ì•ŠìŒ

**ì›ì¸:** Windowsì—ì„œ non-blocking ì…ë ¥ ë¯¸ì§€ì›

**í•´ê²°:**
- Windows: `s` + ENTERë¡œ ì €ì¥, `q` + ENTERë¡œ ì¢…ë£Œ
- Linux/Mac: ìë™ìœ¼ë¡œ ê°ì§€ë¨

### 2. ë¡œë´‡ì´ waypointì— ë„ë‹¬í•˜ì§€ ëª»í•¨

**ì›ì¸:** `waypoint_tolerance`ê°€ ë„ˆë¬´ ì‘ìŒ

**í•´ê²°:**
```bash
--policy.waypoint_tolerance=0.02  # ê¸°ë³¸ê°’ 0.01ì—ì„œ ì¦ê°€
```

### 3. ì›€ì§ì„ì´ ë„ˆë¬´ ëŠë¦¼

**ì›ì¸:** `waypoint_speed`ê°€ ë„ˆë¬´ ì‘ìŒ

**í•´ê²°:**
```bash
--policy.waypoint_speed=0.2  # ê¸°ë³¸ê°’ 0.1ì—ì„œ ì¦ê°€
```

### 4. ë¡œë´‡ì´ ì§„ë™í•¨ (oscillation)

**ì›ì¸:** `waypoint_speed`ê°€ ë„ˆë¬´ í¼

**í•´ê²°:**
```bash
--policy.waypoint_speed=0.05  # ì†ë„ ê°ì†Œ
```

---

## ğŸ“š API ë ˆí¼ëŸ°ìŠ¤

### WaypointPolicy

```python
class WaypointPolicy(HeuristicPolicy):
    def __init__(self, config: HeuristicConfig)
    def reset(self) -> None
    def select_action(self, batch: dict[str, Tensor]) -> Tensor

    # ì†ì„±
    waypoints: list[dict[str, float]]  # ë¡œë“œëœ waypoint ë¦¬ìŠ¤íŠ¸
    current_waypoint_idx: int          # í˜„ì¬ ëª©í‘œ waypoint ì¸ë±ìŠ¤
    waypoints_completed: bool          # ëª¨ë“  waypoint ì™„ë£Œ ì—¬ë¶€
```

### HeuristicConfig (Waypoint ê´€ë ¨)

```python
@dataclass
class HeuristicConfig:
    waypoints_path: str | None = None           # waypoint JSON íŒŒì¼ ê²½ë¡œ
    waypoint_tolerance: float = 0.01            # waypoint ë„ë‹¬ íŒì • ê±°ë¦¬
    waypoint_speed: float = 0.1                 # ì´ë™ ì†ë„ ê³„ìˆ˜ (0~1)
```

---

## ğŸ“ ì˜ˆì œ íŒŒì¼

- **ìŠ¤í¬ë¦½íŠ¸**: `src/lerobot/scripts/lerobot_save_waypoints.py`
- **Policy**: `src/lerobot/policies/heuristic/modeling_heuristic.py`
- **ì˜ˆì œ**: `examples/waypoint_policy_example.py`
- **ì„¤ì •**: `src/lerobot/policies/heuristic/configuration_heuristic.py`

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

1. âœ… Waypoint ì €ì¥ í…ŒìŠ¤íŠ¸
2. âœ… ê°„ë‹¨í•œ pick-and-place ì‘ì—…
3. âœ… íŒŒë¼ë¯¸í„° íŠœë‹
4. âœ… ë°ì´í„° ìˆ˜ì§‘ ë° í•™ìŠµëœ policyì™€ ë¹„êµ

**Happy coding!** ğŸ¤–
